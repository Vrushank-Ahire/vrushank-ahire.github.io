<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Vrushank Ahire</title>
    <meta name="author" content="Vrushank Ahire">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body class="theme-cream">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:68%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Vrushank Ahire
                </p>
                <p>
                  <!-- I'm a senior CS undergrad at the <a href="https://www.iitrpr.ac.in">Indian Institute of Technology (IIT) Ropar</a>, advised by <a href="https://cse.iitrpr.ac.in/mudasir/">Dr. Mudasir Ganaie</a>. My research focuses on multimodal AI, with emphasis on speech, vision, clinical applications, and ML optimization. I've pursued research internships at <a href="https://www.ntu.edu.sg">NTU-Singapore</a>, <a href="https://english.pku.edu.cn">Peking University</a>, and <a href="https://www.monash.edu">Monash University</a>. My work has been published in top venues, including <a href="https://cvpr.thecvf.com">CVPR</a>, <a href="https://www.inns.org/ijcnn-home">IJCNN</a>, <a href="https://hipc.org">HiPC</a>, and in the journals <a href="https://www.sciencedirect.com/journal/neural-networks">Neural Networks</a> and <a href="https://www.sciencedirect.com/journal/pattern-recognition">Pattern Recognition</a>. I'm  a <a href="https://hyundai.scholarsbox.in/">Hyundai Hope Scholarship</a> recipient. -->
                  I'm a senior CS undergrad at the <a href="https://www.iitrpr.ac.in">Indian Institute of Technology (IIT) Ropar</a>, advised by <a href="https://cse.iitrpr.ac.in/mudasir/">Dr. Mudasir Ganaie</a>. My research focuses on multimodal AI, with a particular emphasis on speech and vision, as well as ML optimization. I've gained research experience through internships at <a href="https://www.ntu.edu.sg">NTU-Singapore</a>, <a href="https://english.pku.edu.cn">Peking University</a>, and <a href="https://www.monash.edu">Monash University</a>. My work has been published in top conferences and journals, including <a href="https://cvpr.thecvf.com">CVPR</a>, <a href="https://www.inns.org/ijcnn-home">IJCNN</a>, <a href="https://hipc.org">HiPC</a>, <a href="https://www.sciencedirect.com/journal/neural-networks">Neural Networks</a> and <a href="https://www.sciencedirect.com/journal/pattern-recognition">Pattern Recognition</a>. I am also a recipient of the <a href="https://hyundai.scholarsbox.in/">Hyundai Hope Scholarship</a>.
                </p>
                <p style="text-align:center">
                  <a href="https://mail.google.com/mail/?view=cm&fs=1&to=vahire.works@gmail.com" target="_blank" rel="noopener noreferrer" style="pointer-events:auto;cursor:pointer;" title="Compose email to Vrushank Ahire (opens in new tab)">Email</a> &nbsp;/&nbsp;
                  <a href="data/VrushankAhire-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/VrushankAhire-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.co.in/citations?user=yintsqkAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://orcid.org/0009-0000-1399-2983">ORCID</a> &nbsp;/&nbsp; -->
                  <a href="https://www.linkedin.com/in/vrushank-ahire">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vrushank-ahire">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:32%">
                <div id="profile-toggle" class="profile-toggle" role="button" aria-pressed="false" tabindex="0" aria-label="Toggle profile image and synthesized video">
                  <img src="images/profile_pic.jpg" alt="Profile image of Vrushank Ahire" class="profile-img">
                  <video class="profile-video" src="images/profile_video.mp4" poster="images/profile-poster.jpg" muted loop playsinline aria-label="Synthesized profile video">
                    Your browser does not support the video tag.
                  </video>
                  <button type="button" class="profile-toggle-btn" tabindex="-1" aria-hidden="true">
                    <!-- play icon -->
                    <svg class="icon play" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><path d="M8 5v14l11-7z"/></svg>
                    <!-- pause icon -->
                    <svg class="icon pause" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" style="display:none"><path d="M6 5h4v14H6zM14 5h4v14h-4z"/></svg>
                  </button>
                </div>
                <!-- <p class="profile-caption">Original image ↔ synthesized video</p> -->
                <p style="text-align:center; font-size:12px; color:#666; margin-top:8px;">Image ↔ Synthesized video ◉</p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td class="section-research" style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p class="lead-paragraph">My research spans low-resource and multilingual ASR, multimodal deepfake and emotion recognition, as well as reasoning in LLMs. I also work on clinical AI with EEG and neuroimaging data, along with formulating ML models.</p>
                </td>
              </tr>
            </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 6px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr>
              <td colspan="2" style="padding:8px;"><h3 class="year-heading">2026</h3></td>
            </tr>
            
            <!-- Paper 4: EEG Seizure Detection (NO COLOR) -->
            <tr onmouseout="eeg_stop()" onmouseover="eeg_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='eeg_image'>
                    <img src='images/eeg_seizure_after.jpg' width=100%>
                  </div>
                  <img src='images/eeg_seizure_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function eeg_start() { document.getElementById('eeg_image').style.opacity = "1"; }
                  function eeg_stop() { document.getElementById('eeg_image').style.opacity = "0"; }
                  eeg_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://doi.org/10.1016/j.neunet.2025.108520">
                  <span class="papertitle">A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine</span>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=N_6RJUEAAAAJ">Yogesh Kumar</a>,
                <strong>Vrushank Ahire</strong>,
                <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>
                <br>
                <em>Neural Networks</em>, 2026
                <br>
                <a href="https://arxiv.org/abs/2512.21170">arXiv</a>
                <p></p>
                <p>Universum-enhanced GEPSVM classifiers improving EEG seizure detection through stable eigenvalue formulations.</p>
              </td>
            </tr>
            

            <tr>
              <td colspan="2" style="padding:8px;"><h3 class="year-heading">2025</h3></td>
            </tr>

            <!-- Paper 1: MAVEN (COLOR) -->
            <tr onmouseout="maven_stop()" onmouseover="maven_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='maven_image'>
                    <img src='images/maven_after.jpg' width=100%>
                  </div>
                  <img src='images/maven_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function maven_start() { document.getElementById('maven_image').style.opacity = "1"; }
                  function maven_stop() { document.getElementById('maven_image').style.opacity = "0"; }
                  maven_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2025W/ABAW/html/Ahire_MAVEN_Multi-modal_Attention_for_Valence-Arousal_Emotion_Network_CVPRW_2025_paper.html">
                  <span class="papertitle">MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network</span>
                </a>
                <br>
                <strong>Vrushank Ahire</strong>,
                <a href="https://www.linkedin.com/in/kunal-shah-b78738173">Kunal Shah</a>,
                <a href="https://www.linkedin.com/in/mudasir-khan-20a421202">Mudasir Khan</a>,
                <a href="https://scholar.google.com/citations?user=TjYqD8cAAAAJ">Nikhil Pakhale</a>,
                <a href="https://scholar.google.com/citations?user=HdjoOQIAAAAJ">Lownish Sookha</a>,
                <a href="https://cse.iitrpr.ac.in/mudasir/">Mudasir Ganaie</a>,
                <a href="https://research.monash.edu/en/persons/abhinav-dhall/">Abhinav Dhall</a>
                <br>
                <em>CVPR</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2503.12623">arXiv</a>
                <p></p>
                <p>Bi-directional cross-modal attention across visual/audio/text modalities for dynamic emotion recognition in polar coordinates.</p>
              </td>
            </tr>
            
            <!-- Paper 2: Granular Ball K-Class Twin Support Vector Classifier (NO COLOR) -->
            <tr onmouseout="granular_stop()" onmouseover="granular_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='granular_image'>
                    <img src='images/granular_after.jpg' width=100%>
                  </div>
                  <img src='images/granular_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function granular_start() { document.getElementById('granular_image').style.opacity = "1"; }
                  function granular_stop() { document.getElementById('granular_image').style.opacity = "0"; }
                  granular_stop()
                  </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://doi.org/10.1016/j.patcog.2025.111636">
                  <span class="papertitle">Granular Ball K-Class Twin Support Vector Classifier</span>
                </a>
                <br>
                <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>,
                <strong>Vrushank Ahire</strong>,
                <a href="https://aero.engin.umich.edu/people/girard-anouck/">Anouck Girard</a>
                <br>
                <em>Pattern Recognition</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2412.05438">arXiv</a>
                <p></p>
                <p>Combines granular ball computing with Twin SVM for robust multi-class classification solving two smaller QP problems for efficiency.</p>
              </td>
            </tr>
            
            <!-- Paper 3: SFANet (COLORED) -->
            <tr onmouseout="sfanet_stop()" onmouseover="sfanet_start()" >
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='sfanet_image'>
                    <img src='images/sfanet_after.jpg' width=100%>
                  </div>
                  <img src='images/sfanet_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function sfanet_start() { document.getElementById('sfanet_image').style.opacity = "1"; }
                  function sfanet_stop() { document.getElementById('sfanet_image').style.opacity = "0"; }
                  sfanet_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2510.04630">
                  <span class="papertitle">SFANet: Spatial-Frequency Attention Network for Deepfake Detection</span>
                </a>
                <br>
                <strong>Vrushank Ahire</strong>,
                <a href="https://www.linkedin.com/in/aniruddh-muley-56002a256">Aniruddh Muley</a>,
                <a href="https://in.linkedin.com/in/shivam-zample-a76179323">Shivam Zample</a>,
                <a href="https://in.linkedin.com/in/siddharth-verma-186396259">Siddharth Verma</a>,
                <a href="https://www.linkedin.com/in/pranav-menon-95a95a257">Pranav Menon</a>,
                <a href="https://scholar.google.com/citations?user=aI7hnU8AAAAJ">Surbhi Madan</a>,
                <a href="https://research.monash.edu/en/persons/abhinav-dhall/">Abhinav Dhall</a>
                <br>
                <em>IEEE Signal Processing Cup, ICASSP</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2510.04630">arXiv</a>
                <p></p>
                <p>Ensemble fusing spatial transformers and frequency analysis with conditional face segmentation for state-of-the-art deepfake detection.</p>
              </td>
            </tr>
            

            <!-- Paper 5: Intuitionistic Fuzzy Graph (COLOR) -->
            <tr onmouseout="ifg_stop()" onmouseover="ifg_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ifg_image'>
                    <img src='images/ifg_rvfl_after.jpg' width=100%>
                  </div>
                  <img src='images/ifg_rvfl_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function ifg_start() { document.getElementById('ifg_image').style.opacity = "1"; }
                  function ifg_stop() { document.getElementById('ifg_image').style.opacity = "0"; }
                  ifg_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://doi.org/10.1109/IJCNN64981.2025.11229109">
                  <span class="papertitle">Intuitionistic Fuzzy Graph Embedded Random Vector Functional Link</span>
                </a>
                <br>
                <strong>Vrushank Ahire</strong>,
                <a href="https://scholar.google.com/citations?user=N_6RJUEAAAAJ">Yogesh Kumar</a>,
                <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>
                <br>
                <em>IJCNN</em>, 2025
                <br>
                <p></p>
                <p>Graph-embedded intuitionistic fuzzy RVFL network tackling class imbalance while preserving dataset topology.</p>
              </td>
            </tr>

            <!-- Paper 6: Granular Ball Twin Support Vector Machine with Universum Data (NO COLOR) -->
            <tr onmouseout="universum_stop()" onmouseover="universum_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='universum_image'>
                    <img src='images/granular_universum_after.jpg' width=100%>
                  </div>
                  <img src='images/granular_universum_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function universum_start() { document.getElementById('universum_image').style.opacity = "1"; }
                  function universum_stop() { document.getElementById('universum_image').style.opacity = "0"; }
                  universum_stop()
                  </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://doi.org/10.1016/j.neunet.2025.107974">
                  <span class="papertitle">Granular Ball Twin Support Vector Machine with Universum Data</span>
                </a>
                <br>
                <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a> and
                <strong>Vrushank Ahire</strong>
                <br>
                <em>Neural Networks</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2412.03375">arXiv</a>
                <p></p>
                <p>Integrates granular balls concept and Universum learning into Twin SVM for noise-robust classification with enhanced domain knowledge.</p>
              </td>
            </tr>
            <tr>
              <td colspan="2" style="padding:8px;"><h3 class="year-heading">2024</h3></td>
            </tr>
            <!-- Paper 7: Random Adaptive Cache Placement Policy (COLORED) -->
            <tr onmouseout="cache_stop()" onmouseover="cache_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='cache_image'>
                    <img src='images/random_cache_after.jpg' width=100%>
                  </div>
                  <img src='images/random_cache_before.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function cache_start() { document.getElementById('cache_image').style.opacity = "1"; }
                  function cache_stop() { document.getElementById('cache_image').style.opacity = "0"; }
                  cache_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://doi.org/10.1109/HiPCW63042.2024.00058">
                  <span class="papertitle">Random Adaptive Cache Placement Policy</span>
                </a>
                <br>
                <strong>Vrushank Ahire</strong>,
                <a href="https://www.linkedin.com/in/pranav-menon-95a95a257">Pranav Menon</a>,
                <a href="https://www.linkedin.com/in/aniruddh-muley-56002a256">Aniruddh Muley</a>,
                <a href="https://scholar.google.com/citations?user=GbejLhIAAAAJ">Abhinandan S Prasad</a>
                <br>
                <em>IEEE HiPC</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2502.02349">arXiv</a>
                <p></p>
                <p>Hybrid cache replacement algorithm combining random allocation with V-Way cache achieving up to 80.82% hit rates.</p>
              </td>
            </tr>

          </tbody></table>

          
				
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  design adapted from Jon Barron's <a href="https://jonbarron.info/">website</a></p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <script>
    (function(){
      const wrapper = document.getElementById('profile-toggle');
      if(!wrapper) return;
      const video = wrapper.querySelector('video.profile-video');
      const img = wrapper.querySelector('img.profile-img');
      function toggle(ev){
        const show = wrapper.classList.toggle('show-video');
        wrapper.setAttribute('aria-pressed', String(show));
        if(show){
          // play video, ensure muted for autoplay policies
          video.muted = true;
          const p = video.play();
          if(p && p.catch){ p.catch(()=>{}); }
        } else {
          video.pause();
          video.currentTime = 0;
        }
      }
      wrapper.addEventListener('click', toggle);
      const btn = wrapper.querySelector('.profile-toggle-btn');
      if(btn){ btn.addEventListener('click', function(e){ e.stopPropagation(); toggle(); }); }
      wrapper.addEventListener('keydown', function(e){ if(e.key==='Enter' || e.key===' '){ e.preventDefault(); toggle(); } });
    })();
    </script>

  </body>
</html>
