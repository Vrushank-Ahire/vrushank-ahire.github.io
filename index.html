<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Vrushank Ahire</title>
    <meta name="author" content="Vrushank Ahire">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
      /* Import Google Fonts for better typography */
      @import url('https://fonts.googleapis.com/css2?family=Crimson+Pro:wght@400;500;600&family=Inter:wght@400;500;600&display=swap');
      
      /* Enhanced paper section styles */
      .papertitle {
        font-family: 'Crimson Pro', Georgia, serif;
        font-size: 18px;
        font-weight: 600;
        color: #2c5f8d; /* Blue color for clickability */
        line-height: 1.4;
        letter-spacing: -0.01em;
        transition: all 0.2s ease;
        text-decoration: none;
        display: inline-block;
        margin-bottom: 4px;
      }
      
      .papertitle:hover {
        color: #1e4564; /* Darker blue on hover */
        text-decoration: underline;
        text-decoration-thickness: 2px;
        text-underline-offset: 3px;
      }
      
.paper-row {
  display: grid;
  grid-template-columns: 180px 1fr;
  gap: 28px;
  padding: 24px;
  margin: 16px 0;
  border-radius: 8px;
  transition: all 0.3s ease;
  background: #ffffff;
  border: 1px solid #e2e8f0;
}
      
      .paper-row:hover {
        background: #f8f9fa;
        border-color: #e0e0e0;
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(0,0,0,0.08);
      }
      
      .paper-row.highlight-yellow {
        background: linear-gradient(135deg, #fff9e6 0%, rgba(255, 249, 230, 0.5) 100%);
      }
      
      .paper-row.highlight-yellow:hover {
        background: linear-gradient(135deg, #fff9e6 0%, rgba(255, 249, 230, 0.7) 100%);
      }
      
      .paper-image {
        position: relative;
      }
      
      .one {
        width: 180px;
        height: 180px;
        position: relative;
        overflow: hidden;
        border-radius: 6px;
        box-shadow: 0 3px 10px rgba(0,0,0,0.08);
        transition: all 0.3s ease;
        border: 1px solid #eaeaea;
      }
      
      .paper-row:hover .one {
        box-shadow: 0 6px 20px rgba(0,0,0,0.12);
        transform: scale(1.03);
      }
      
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0;
        transition: opacity 0.4s ease;
      }
      
      .one img,
      .two img {
        width: 100%;
        height: 100%;
        object-fit: cover;
        border-radius: 5px;
      }
      
      .paper-content {
        display: flex;
        flex-direction: column;
        gap: 6px;
      }
      
      .paper-authors {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        font-size: 14.5px;
        line-height: 1.6;
        color: #444;
        margin-top: 2px;
      }
      
      .paper-authors a {
        color: #2c5f8d;
        text-decoration: none;
        transition: color 0.2s ease;
      }
      
      .paper-authors a:hover {
        color: #1e4564;
        text-decoration: underline;
      }
      
      .paper-venue {
        font-family: 'Inter', monospace;
        font-size: 13px;
        color: #c17817;
        font-weight: 600;
        letter-spacing: 0.02em;
        margin: 4px 0 !important;
        padding: 2px 0;
      }
      
      .paper-links {
        margin: 10px 0 0 !important;
      }
      
      .paper-links a {
        font-family: 'Inter', sans-serif;
        font-size: 12px;
        font-weight: 400;
        padding: 5px 14px;
        background: #f0f4f8;
        color: #2c5f8d;
        border-radius: 4px;
        display: inline-block;
        margin-right: 8px;
        margin-top: 4px;
        transition: all 0.2s ease;
        border: 1px solid #d1e0f0;
        text-decoration: none;
      }
      
      .paper-links a:hover {
        background: #2c5f8d;
        color: white;
        border-color: #2c5f8d;
        transform: translateY(-1px);
        box-shadow: 0 3px 8px rgba(44, 95, 141, 0.2);
      }
      
      .paper-row p {
        margin: 10px 0 0;
        font-family: 'Inter', sans-serif;
        font-size: 14.5px;
        line-height: 1.65;
        color: #555;
        max-width: 90%;
      }
      
      .year-heading {
        font-family: 'Crimson Pro', Georgia, serif;
        font-size: 26px;
        font-weight: 600;
        margin: 25px 0 15px;
        padding-bottom: 12px;
        border-bottom: 2px solid #e5e3dc;
        color: #1a1a1a;
        position: relative;
        letter-spacing: -0.01em;
      }
      
      .year-heading::before {
        content: '';
        position: absolute;
        bottom: -2px;
        left: 0;
        width: 80px;
        height: 3px;
        background: #2c5f8d;
        border-radius: 2px;
      }
      
      /* Section header */
      .section-research h2 {
        font-family: 'Crimson Pro', Georgia, serif;
        font-size: 20px;
        font-weight: 60;
        margin: 0 0 16px;
        color: #1a1a1a;
        letter-spacing: -0.02em;
      }
      
      .lead-paragraph {
        font-family: 'Inter', sans-serif;
        font-size: 14px;
        line-height: 1.7;
        color: #4a4a4a;
        max-width: 95%;
      }

      
      
body {
  font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
  color: #2d3748;
  background: #e3ae6d;
}


.container {
  max-width: 800px;
  margin: 0 auto;
  padding: 20px;
}

.paper-row {
  background: #ffffff;
  border: 1px solid #e2e8f0;
}

.paper-row:hover {
  background: #f8fafc;
  border-color: #cbd5e0;
}
      
      a {
        color: #2c5f8d;
        text-decoration: none;
        transition: color 0.2s ease;
      }
      
      a:hover {
        color: #1e4564;
        text-decoration: underline;
      }
      
      strong {
        color: #1a1a1a;
        font-weight: 600;
      }
      
      @media (max-width: 768px) {
  /* Only target first row (profile row) */
  table tbody tr:first-child {
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  table tbody tr:first-child td {
    width: 100% !important;
    text-align: center;
    display: block;
  }

  /* Move image td above text td */
  table tbody tr:first-child td:nth-child(2) {
    order: 1;
  }

  table tbody tr:first-child td:nth-child(1) {
    order: 2;
  }

  .profile-img {
    margin: 10px auto 15px auto;
    display: block;
  }
        .paper-row {
          grid-template-columns: 1fr;
          gap: 22px;
          padding: 22px;
        }
        
        .one {
          width: 100%;
          max-width: 280px;
          height: 280px;
          margin: 0 auto;
        }
        
        .paper-content {
          text-align: left;
        }
        
        .paper-links {
          text-align: left;
        }
        
        .year-heading {
          font-size: 22px;
          margin: 40px 0 20px;
        }
        
        .section-research h2 {
          font-size: 28px;
        }
        
        .papertitle {
          font-size: 17px;
        }
      }
      
      @media (max-width: 480px) {
        .paper-row {
          padding: 18px;
          margin: 12px 0;
        }
        
        .one {
          height: 240px;
        }
        
        .paper-links a {
          font-size: 12.5px;
          padding: 4px 12px;
          margin-right: 6px;
        }
        
        .papertitle {
          font-size: 16px;
        }
        
        .paper-authors {
          font-size: 14px;
        }
      }
    </style>
  </head>

  <body class="theme-cream">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:68%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Vrushank Ahire
                </p>
                <p class="intro-text">
                  I'm a senior CS undergrad at the <a href="https://www.iitrpr.ac.in">Indian Institute of Technology (IIT) Ropar</a>, advised by <a href="https://cse.iitrpr.ac.in/mudasir/">Dr. Mudasir Ganaie</a>. My research focuses on multimodal AI, with a particular emphasis on speech and vision, as well as ML optimization. I've gained research experience through internships at <a href="https://www.ntu.edu.sg">NTU-Singapore</a>, <a href="https://english.pku.edu.cn">Peking University</a>, and <a href="https://www.monash.edu">Monash University</a>. My work has been published in top conferences and journals, including <a href="https://cvpr.thecvf.com">CVPR</a>, <a href="https://www.inns.org/ijcnn-home">IJCNN</a>, <a href="https://hipc.org">HiPC</a>, <a href="https://www.sciencedirect.com/journal/neural-networks">Neural Networks</a> and <a href="https://www.sciencedirect.com/journal/pattern-recognition">Pattern Recognition</a>. I am also a recipient of the <a href="https://hyundai.scholarsbox.in/">Hyundai Hope Scholarship</a>.
                </p>
                <p style="text-align:center">
                  <a href="https://mail.google.com/mail/?view=cm&fs=1&to=vahire.works@gmail.com" target="_blank" rel="noopener noreferrer" style="pointer-events:auto;cursor:pointer;" title="Compose email to Vrushank Ahire (opens in new tab)">Email</a> &nbsp;/&nbsp;
                  <a href="data/VrushankAhire-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.co.in/citations?user=yintsqkAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/vrushank-ahire">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vrushank-ahire">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:32%">
                <img src="images/profile_pic.jpg" alt="Vrushank Ahire" class="profile-img">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td class="section-research" style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p class="lead-paragraph">My research spans low-resource and multilingual ASR, multimodal deepfake and emotion recognition, as well as reasoning in LLMs. I also work on clinical AI with EEG and neuroimaging data, along with formulating ML models.</p>
                </td>
              </tr>
            </tbody></table>
          
          <!-- 2026 Papers -->
          <div style="margin: 24px 0;">
            <h3 class="year-heading">2026</h3>
            
            <div class="paper-row highlight-yellow" onmouseout="eeg_stop()" onmouseover="eeg_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='eeg_image'>
                    <img src='images/eeg_seizure_after.jpg' alt="EEG Seizure Detection">
                  </div>
                  <img src='images/eeg_seizure_before.jpg' alt="EEG Seizure Detection">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://doi.org/10.1016/j.neunet.2025.108520" class="papertitle">
                  A Unified Framework for EEG Seizure Detection Using Universum-Integrated Generalized Eigenvalues Proximal Support Vector Machine
                </a>
                <div class="paper-authors">
                  <a href="https://scholar.google.com/citations?user=N_6RJUEAAAAJ">Yogesh Kumar</a>,
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>
                </div>
                <div class="paper-venue">Neural Networks, 2026</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2512.21170">arXiv</a>
                </div>
                <p>Universum-enhanced GEPSVM classifiers improving EEG seizure detection through stable eigenvalue formulations.</p>
              </div>
            </div>
          </div>
          
          <!-- 2025 Papers -->
          <div style="margin: 24px 0;">
            <h3 class="year-heading">2025</h3>
            
            <div class="paper-row" onmouseout="maven_stop()" onmouseover="maven_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='maven_image'>
                    <img src='images/maven_after.jpg' alt="MAVEN">
                  </div>
                  <img src='images/maven_before.jpg' alt="MAVEN">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://openaccess.thecvf.com/content/CVPR2025W/ABAW/html/Ahire_MAVEN_Multi-modal_Attention_for_Valence-Arousal_Emotion_Network_CVPRW_2025_paper.html" class="papertitle">
                  MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network
                </a>
                <div class="paper-authors">
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://www.linkedin.com/in/kunal-shah-b78738173">Kunal Shah</a>,
                  <a href="https://www.linkedin.com/in/mudasir-khan-20a421202">Mudasir Khan</a>,
                  <a href="https://scholar.google.com/citations?user=TjYqD8cAAAAJ">Nikhil Pakhale</a>,
                  <a href="https://scholar.google.com/citations?user=HdjoOQIAAAAJ">Lownish Sookha</a>,
                  <a href="https://cse.iitrpr.ac.in/mudasir/">Mudasir Ganaie</a>,
                  <a href="https://research.monash.edu/en/persons/abhinav-dhall/">Abhinav Dhall</a>
                </div>
                <div class="paper-venue">CVPR, 2025</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2503.12623">arXiv</a>
                </div>
                <p>Bi-directional cross-modal attention across visual/audio/text modalities for dynamic emotion recognition in polar coordinates.</p>
              </div>
            </div>
            
            <div class="paper-row highlight-yellow" onmouseout="granular_stop()" onmouseover="granular_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='granular_image'>
                    <img src='images/granular_after.jpg' alt="Granular Ball">
                  </div>
                  <img src='images/granular_before.jpg' alt="Granular Ball">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://doi.org/10.1016/j.patcog.2025.111636" class="papertitle">
                  Granular Ball K-Class Twin Support Vector Classifier
                </a>
                <div class="paper-authors">
                  <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>,
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://aero.engin.umich.edu/people/girard-anouck/">Anouck Girard</a>
                </div>
                <div class="paper-venue">Pattern Recognition, 2025</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2412.05438">arXiv</a>
                </div>
                <p>Combines granular ball computing with Twin SVM for robust multi-class classification solving two smaller QP problems for efficiency.</p>
              </div>
            </div>
            
            <div class="paper-row" onmouseout="sfanet_stop()" onmouseover="sfanet_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='sfanet_image'>
                    <img src='images/sfanet_after.jpg' alt="SFANet">
                  </div>
                  <img src='images/sfanet_before.jpg' alt="SFANet">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://arxiv.org/abs/2510.04630" class="papertitle">
                  SFANet: Spatial-Frequency Attention Network for Deepfake Detection
                </a>
                <div class="paper-authors">
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://www.linkedin.com/in/aniruddh-muley-56002a256">Aniruddh Muley</a>,
                  <a href="https://in.linkedin.com/in/shivam-zample-a76179323">Shivam Zample</a>,
                  <a href="https://in.linkedin.com/in/siddharth-verma-186396259">Siddharth Verma</a>,
                  <a href="https://www.linkedin.com/in/pranav-menon-95a95a257">Pranav Menon</a>,
                  <a href="https://scholar.google.com/citations?user=aI7hnU8AAAAJ">Surbhi Madan</a>,
                  <a href="https://research.monash.edu/en/persons/abhinav-dhall/">Abhinav Dhall</a>
                </div>
                <div class="paper-venue">IEEE Signal Processing Cup, ICASSP, 2025</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2510.04630">arXiv</a>
                </div>
                <p>Ensemble fusing spatial transformers and frequency analysis with conditional face segmentation for state-of-the-art deepfake detection.</p>
              </div>
            </div>
            
            <div class="paper-row highlight-yellow" onmouseout="ifg_stop()" onmouseover="ifg_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='ifg_image'>
                    <img src='images/ifg_rvfl_after.jpg' alt="Intuitionistic Fuzzy Graph">
                  </div>
                  <img src='images/ifg_rvfl_before.jpg' alt="Intuitionistic Fuzzy Graph">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://doi.org/10.1109/IJCNN64981.2025.11229109" class="papertitle">
                  Intuitionistic Fuzzy Graph Embedded Random Vector Functional Link
                </a>
                <div class="paper-authors">
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://scholar.google.com/citations?user=N_6RJUEAAAAJ">Yogesh Kumar</a>,
                  <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a>
                </div>
                <div class="paper-venue">IJCNN, 2025</div>
                <p>Graph-embedded intuitionistic fuzzy RVFL network tackling class imbalance while preserving dataset topology.</p>
              </div>
            </div>
            
            <div class="paper-row" onmouseout="universum_stop()" onmouseover="universum_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='universum_image'>
                    <img src='images/granular_universum_after.jpg' alt="Granular Ball Universum">
                  </div>
                  <img src='images/granular_universum_before.jpg' alt="Granular Ball Universum">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://doi.org/10.1016/j.neunet.2025.107974" class="papertitle">
                  Granular Ball Twin Support Vector Machine with Universum Data
                </a>
                <div class="paper-authors">
                  <a href="https://cse.iitrpr.ac.in/mudasir/">MA Ganaie</a> and
                  <strong>Vrushank Ahire</strong>
                </div>
                <div class="paper-venue">Neural Networks, 2025</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2412.03375">arXiv</a>
                </div>
                <p>Integrates granular balls concept and Universum learning into Twin SVM for noise-robust classification with enhanced domain knowledge.</p>
              </div>
            </div>
          </div>
          
          <!-- 2024 Papers -->
          <div style="margin: 24px 0;">
            <h3 class="year-heading">2024</h3>
            
            <div class="paper-row highlight-yellow" onmouseout="cache_stop()" onmouseover="cache_start()">
              <div class="paper-image">
                <div class="one">
                  <div class="two" id='cache_image'>
                    <img src='images/random_cache_after.jpg' alt="Cache Placement">
                  </div>
                  <img src='images/random_cache_before.jpg' alt="Cache Placement">
                </div>
              </div>
              <div class="paper-content">
                <a href="https://doi.org/10.1109/HiPCW63042.2024.00058" class="papertitle">
                  Random Adaptive Cache Placement Policy
                </a>
                <div class="paper-authors">
                  <strong>Vrushank Ahire</strong>,
                  <a href="https://www.linkedin.com/in/pranav-menon-95a95a257">Pranav Menon</a>,
                  <a href="https://www.linkedin.com/in/aniruddh-muley-56002a256">Aniruddh Muley</a>,
                  <a href="https://scholar.google.com/citations?user=GbejLhIAAAAJ">Abhinandan S Prasad</a>
                </div>
                <div class="paper-venue">IEEE HiPC, 2024</div>
                <div class="paper-links">
                  <a href="https://arxiv.org/abs/2502.02349">arXiv</a>
                </div>
                <p>Hybrid cache replacement algorithm combining random allocation with V-Way cache achieving up to 80.82% hit rates.</p>
              </div>
            </div>
          </div>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  design adapted from Jon Barron's <a href="https://jonbarron.info/">website</a></p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <script>
    (function(){
      const wrapper = document.getElementById('profile-toggle');
      if(!wrapper) return;
      const video = wrapper.querySelector('video.profile-video');
      const img = wrapper.querySelector('img.profile-img');
      function toggle(ev){
        const show = wrapper.classList.toggle('show-video');
        wrapper.setAttribute('aria-pressed', String(show));
        if(show){
          // play video, ensure muted for autoplay policies
          video.muted = true;
          const p = video.play();
          if(p && p.catch){ p.catch(()=>{}); }
        } else {
          video.pause();
          video.currentTime = 0;
        }
      }
      wrapper.addEventListener('click', toggle);
      const btn = wrapper.querySelector('.profile-toggle-btn');
      if(btn){ btn.addEventListener('click', function(e){ e.stopPropagation(); toggle(); }); }
      wrapper.addEventListener('keydown', function(e){ if(e.key==='Enter' || e.key===' '){ e.preventDefault(); toggle(); } });
    })();
    </script>

    <script>
      // Hover effects for papers
      function eeg_start() { document.getElementById('eeg_image').style.opacity = "1"; }
      function eeg_stop() { document.getElementById('eeg_image').style.opacity = "0"; }
      function maven_start() { document.getElementById('maven_image').style.opacity = "1"; }
      function maven_stop() { document.getElementById('maven_image').style.opacity = "0"; }
      function granular_start() { document.getElementById('granular_image').style.opacity = "1"; }
      function granular_stop() { document.getElementById('granular_image').style.opacity = "0"; }
      function sfanet_start() { document.getElementById('sfanet_image').style.opacity = "1"; }
      function sfanet_stop() { document.getElementById('sfanet_image').style.opacity = "0"; }
      function ifg_start() { document.getElementById('ifg_image').style.opacity = "1"; }
      function ifg_stop() { document.getElementById('ifg_image').style.opacity = "0"; }
      function universum_start() { document.getElementById('universum_image').style.opacity = "1"; }
      function universum_stop() { document.getElementById('universum_image').style.opacity = "0"; }
      function cache_start() { document.getElementById('cache_image').style.opacity = "1"; }
      function cache_stop() { document.getElementById('cache_image').style.opacity = "0"; }
      
      // Initialize all hover effects to off
      eeg_stop();
      maven_stop();
      granular_stop();
      sfanet_stop();
      ifg_stop();
      universum_stop();
      cache_stop();
    </script>

  </body>
</html>